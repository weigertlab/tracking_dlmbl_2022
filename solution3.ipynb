{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d957715b",
   "metadata": {},
   "source": [
    "# Exercise 3/3: Tracking with an integer linear program (ILP)\n",
    "\n",
    "You could also run this notebook on your laptop, a GPU is not needed :)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd566a93",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force keras to run on CPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams[\"image.interpolation\"] = \"none\"\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 6)\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap\n",
    "from stardist.plot import render_label\n",
    "from stardist.models import StarDist2D\n",
    "from stardist import _draw_polygons\n",
    "from csbdeep.utils import normalize\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import cvxpy as cp\n",
    "\n",
    "import napari\n",
    "import networkx as nx\n",
    "\n",
    "lbl_cmap = random_label_cmap()\n",
    "# Pretty tqdm progress bars \n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image\", lbl_title=\"label\", **kwargs):\n",
    "    fig, (ai,al) = plt.subplots(1,2, gridspec_kw=dict(width_ratios=(1,1)))\n",
    "    im = ai.imshow(img, cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)\n",
    "    ai.axis(\"off\")\n",
    "    al.imshow(render_label(lbl, img=.3*img, normalize_img=False, cmap=lbl_cmap))\n",
    "    al.set_title(lbl_title)\n",
    "    al.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def preprocess(X, Y, axis_norm=(0,1)):\n",
    "    # normalize channels independently\n",
    "    X = np.stack([normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X, leave=True, desc=\"Normalize images\")])\n",
    "    # fill holes in labels\n",
    "    Y = np.stack([fill_label_holes(y) for y in tqdm(Y, leave=True, desc=\"Fill holes in labels\")])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052dd77",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69094b-b70b-4e4d-98cf-47b09e95d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"data/exercise3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack([imread(str(p)) for p in sorted((base_path/ \"images\").glob(\"*.tif\"))])\n",
    "y = np.stack([imread(str(p)) for p in sorted((base_path/ \"gt_tracking\").glob(\"*.tif\"))])\n",
    "assert len(x) == len(x)\n",
    "print(f\"Number of images: {len(x)}\")\n",
    "print(f\"Image shape: {x[0].shape}\")\n",
    "links = pd.read_csv(base_path / \"gt_tracking\" / \"man_track.txt\", names=[\"track_id\", \"from\", \"to\", \"parent_id\"], sep=\" \")\n",
    "print(\"Links\")\n",
    "links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a5a49-1b39-46ad-a409-8fa5911c4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = preprocess(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plot_img_label(x[idx], y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d07035",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x, name=\"image\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57799f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\"><h3>Napari in a jupyter notebook:</h3>\n",
    "    \n",
    "- To have napari working in a jupyter notebook, you need to use up-to-date versions of napari, pyqt and pyqt5, as is the case in the conda environments provided together with this exercise.\n",
    "- When you are coding and debugging, close the napari viewer with `viewer.close()` to avoid problems with the two event loops of napari and jupyter.\n",
    "- **If a cell is not executed (empty square brackets on the left of a cell) despite you running it, running it a second time right after will usually work.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75346521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracks(viewer, y, links=None, name=\"\"):\n",
    "    \"\"\"Utility function to visualize segmentation and tracks\"\"\"\n",
    "    max_label = max(links.max(), y.max()) if links is not None else y.max()\n",
    "    colorperm = np.random.default_rng(42).permutation(np.arange(1, max_label + 2))\n",
    "    tracks = []\n",
    "    for t, frame in enumerate(y):\n",
    "        centers = skimage.measure.regionprops(frame)\n",
    "        for c in centers:\n",
    "            tracks.append([colorperm[c.label], t, int(c.centroid[0]), int(c.centroid[1])])\n",
    "    tracks = np.array(tracks)\n",
    "    tracks = tracks[tracks[:, 0].argsort()]\n",
    "    \n",
    "    graph = {}\n",
    "    if links is not None:\n",
    "        divisions = links[links[:,3] != 0]\n",
    "        for d in divisions:\n",
    "            if colorperm[d[0]] not in tracks[:, 0] or colorperm[d[3]] not in tracks[:, 0]:\n",
    "                continue\n",
    "            graph[colorperm[d[0]]] = [colorperm[d[3]]]\n",
    "\n",
    "    viewer.add_labels(y, name=f\"{name}_detections\")\n",
    "    viewer.layers[f\"{name}_detections\"].contour = 3\n",
    "    viewer.add_tracks(tracks, name=f\"{name}_tracks\", graph=graph)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tracks(viewer, y, links.to_numpy(), \"ground_truth\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a97739",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Object detection using a pre-trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96220b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "# model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")\n",
    "model = StarDist2D(None, name=\"stardist_breast_cancer\", basedir=\"models\")\n",
    "(detections, details), (prob, _) = model.predict_instances(x[idx], scale=(1, 1), nms_thresh=0.3, prob_thresh=0.3, return_predict=True)\n",
    "plot_img_label(x[idx], detections, lbl_title=\"detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be00541",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord, points, polygon_prob = details['coord'], details['points'], details['prob']\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.title(\"Predicted Polygons\")\n",
    "_draw_polygons(coord, points, polygon_prob, show_dist=True)\n",
    "plt.imshow(x[idx], cmap='gray'); plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Object center probability\")\n",
    "plt.imshow(prob, cmap='magma'); plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac05fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_thres = 0.3\n",
    "nms_thres = 0.6\n",
    "scale = (1.0, 1.0)\n",
    "pred = [model.predict_instances(xi, show_tile_progress=False, scale=scale, nms_thresh=nms_thres, prob_thresh=prob_thres, return_predict=True)\n",
    "              for xi in tqdm(x)]\n",
    "detections = np.array([xi[0][0] for xi in pred])\n",
    "centers = [xi[0][1][\"points\"] for xi in pred]\n",
    "center_probs = [xi[0][1][\"prob\"] for xi in pred]\n",
    "prob_maps = np.stack([xi[1][0] for xi in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, y, links.to_numpy(), \"ground_truth\");\n",
    "viewer.add_labels(detections, name=f\"detections_scale_{scale}_nmsthres_{nms_thres}\");\n",
    "# viewer.add_image(prob_maps, colormap=\"magma\", scale=(2,2), opacity=0.2);\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d77db2",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Build a candidate graph from the detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(detections, max_distance, detection_probs=None, drift=(0,0)):\n",
    "    \"\"\"\n",
    "    \n",
    "        detection_probs: list of arrays, corresponding to ordered ids in detections.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    n_v = 0\n",
    "    \n",
    "    luts = []\n",
    "    draw_positions = {}\n",
    "    \n",
    "    for t, d in enumerate(detections):\n",
    "        frame = skimage.segmentation.relabel_sequential(d)[0]\n",
    "        regions = skimage.measure.regionprops(frame)\n",
    "        lut = {}\n",
    "        for i, r in enumerate(regions):\n",
    "            draw_pos = np.array([t, d.shape[0] - r.centroid[0]])\n",
    "            weight = detection_probs[t][i] if detection_probs else 1\n",
    "            G.add_node(n_v, time=t, detection_id=r.label, weight=weight, draw_position=draw_pos)\n",
    "            draw_positions[n_v] = draw_pos\n",
    "            lut[r.label] = n_v\n",
    "            n_v += 1\n",
    "        luts.append(lut)\n",
    "\n",
    "    n_e = 0\n",
    "    for t, (d0, d1) in enumerate(zip(detections, detections[1:])):\n",
    "        f0 = skimage.segmentation.relabel_sequential(d0)[0]\n",
    "        r0 = skimage.measure.regionprops(f0)\n",
    "        c0 = [np.array(r.centroid) for r in r0]\n",
    "\n",
    "        f1 = skimage.segmentation.relabel_sequential(d1)[0]\n",
    "        r1 = skimage.measure.regionprops(f1)\n",
    "        c1 = [np.array(r.centroid) for r in r1]\n",
    "\n",
    "        for _r0, _c0 in zip(r0, c0):\n",
    "            for _r1, _c1 in zip(r1, c1):\n",
    "                dist = np.linalg.norm(_c0 - _c1)\n",
    "                if dist < max_distance:\n",
    "                    G.add_edge(\n",
    "                        luts[t][_r0.label],\n",
    "                        luts[t+1][_r1.label],\n",
    "                        # normalized euclidian distance\n",
    "                        weight = np.linalg.norm(_c0 + np.array(drift) - _c1) / max_distance,\n",
    "                        edge_id = n_e,\n",
    "                    )\n",
    "                    n_e += 1\n",
    "    \n",
    "    return G, luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bda375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_tracks(detections, links=None):\n",
    "    \"\"\"\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    n_v = 0\n",
    "    \n",
    "    luts = []\n",
    "    draw_positions = {}\n",
    "    \n",
    "    for t, d in enumerate(detections):\n",
    "        frame = d\n",
    "        regions = skimage.measure.regionprops(frame)\n",
    "        lut = {}\n",
    "        for r in regions:\n",
    "            draw_pos = np.array([t, d.shape[0] - r.centroid[0]])\n",
    "            G.add_node(n_v, time=t, detection_id=r.label, weight=1, draw_position=draw_pos)\n",
    "            draw_positions[n_v] = draw_pos\n",
    "            lut[r.label] = n_v\n",
    "            n_v += 1\n",
    "        luts.append(lut)\n",
    "        \n",
    "    n_e = 0\n",
    "    for t, (d0, d1) in enumerate(zip(detections, detections[1:])):\n",
    "        f0 = d0\n",
    "        r0 = skimage.measure.regionprops(f0)\n",
    "        c0 = [np.array(r.centroid) for r in r0]\n",
    "        # print(c0)\n",
    "\n",
    "        f1 = d1\n",
    "        r1 = skimage.measure.regionprops(f1)\n",
    "        c1 = [np.array(r.centroid) for r in r1]\n",
    "        # print(c1)\n",
    "\n",
    "        for _r0, _c0 in zip(r0, c0):\n",
    "            for _r1, _c1 in zip(r1, c1):\n",
    "                if _r0.label == _r1.label:\n",
    "                    G.add_edge(\n",
    "                        luts[t][_r0.label],\n",
    "                        luts[t+1][_r1.label],\n",
    "                        # normalized euclidian distance\n",
    "                        weight = np.linalg.norm(_c0 - _c1),\n",
    "                        edge_id = n_e,\n",
    "                    )\n",
    "                    n_e += 1\n",
    "    \n",
    "    if links is not None:\n",
    "        divisions = links[links[:,3] != 0]\n",
    "        for d in divisions:\n",
    "            if d[1] > 0 and d[1] < detections.shape[0]:\n",
    "                try:\n",
    "                    G.add_edge(luts[d[1] - 1][d[3]], luts[d[1]][d[0]])\n",
    "                    # print(\"Division edge\")\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                    # print(d)\n",
    "                    # print(\"Can't find parent in previous frame (cropping, disappearing tracks).\")\n",
    "    \n",
    "    return G, luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e935bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(g, title=None, ax=None, height=None):\n",
    "    pos = {i: g.nodes[i][\"draw_position\"] for i in g.nodes}\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.set_title(title)\n",
    "    nx.draw(g, pos=pos, with_labels=True, ax=ax)\n",
    "\n",
    "    ax.set_axis_on()\n",
    "    ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "    if height:\n",
    "        ax.set_ylim(0, height)\n",
    "    \n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.set_ylabel(\"y (spatial)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_graph, gt_luts = build_graph_from_tracks(y, links.to_numpy())\n",
    "candidate_graph, candidate_luts = build_graph(detections, max_distance=50, detection_probs=center_probs, drift=(-6 , 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1,2, figsize=(24, 12))\n",
    "draw_graph(gt_graph, \"Ground truth graph\", ax=ax0, height=detections[0].shape[0])\n",
    "draw_graph(candidate_graph, \"Candidate graph\", ax=ax1, height=detections[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd0b30-c577-47f7-b371-9191efcb430b",
   "metadata": {},
   "source": [
    "## Network flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a401b-33a7-4f4f-b770-2d2faba8c2f3",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 3.1\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 3.1: Write the flow constraint of the network flow</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f5640-c911-4557-b72a-5aff7bd60535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Exercise 3.1\n",
    "\n",
    "def graph2ilp_flow(graph, hyperparams):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    # Extend the graph with a single appear and death node\n",
    "    graph_flow = nx.DiGraph()\n",
    "    graph_flow.add_node(\"appear\", weight=0)\n",
    "    graph_flow.add_node(\"death\", weight=0)\n",
    "    \n",
    "    for n, time in graph.nodes(data=\"time\"):\n",
    "        if time == 0:\n",
    "            # Connect all nodes in initial frame to appear node\n",
    "            graph_flow.add_node(n, weight=0)\n",
    "            graph_flow.add_edge(\"appear\", n, weight=0)\n",
    "        elif time == len(detections) - 1:\n",
    "            # Connect all nodes in last frame to death node\n",
    "            graph_flow.add_node(n, weight=0)\n",
    "            graph_flow.add_edge(n, \"death\", weight=0)\n",
    "        \n",
    "        \n",
    "    edge_to_idx = {edge: i for i, edge in enumerate(graph.edges)}\n",
    "    edge_to_idx_flow = {edge: i for i, edge in enumerate(graph_flow.edges)}\n",
    "\n",
    "    E = graph.number_of_edges()\n",
    "    V = graph.number_of_nodes()\n",
    "    E_flow = graph_flow.number_of_edges()\n",
    "    x = cp.Variable(E + V + E_flow, boolean=True)\n",
    "    \n",
    "    c_e = hyperparams[\"edge_factor\"] * np.array([graph.get_edge_data(*e)[\"weight\"] for e in graph.edges])\n",
    "    c_v = hyperparams[\"node_factor\"] * np.array([v for k, v in graph.nodes(data=\"weight\")])\n",
    "    c_e_flow = hyperparams[\"edge_factor\"] * np.array([graph_flow.get_edge_data(*e)[\"weight\"] for e in graph_flow.edges])  # weight set to 0 above\n",
    "    \n",
    "    # print(c_v)\n",
    "    c = np.concatenate([c_e, c_v, c_e_flow])\n",
    "    \n",
    "    # constraint matrices: {E or V} x (E + V + E_flow)\n",
    "    # columns: c_e, c_v, c_e_flow\n",
    "    \n",
    "    # Edge consistency constraint\n",
    "    A0 = np.zeros((E, E + V + E_flow))\n",
    "    A0[:E, :E] = 2 * np.eye(E)\n",
    "    for edge in graph.edges:\n",
    "        edge_id = edge_to_idx[edge]\n",
    "        A0[edge_id, E + edge[0]] = -1\n",
    "        A0[edge_id, E + edge[1]] = -1\n",
    "    \n",
    "    # Node consistency constraint\n",
    "    A1 = np.zeros((V, E + V + E_flow))\n",
    "    A1[:V, E:E+V] = 2 * np.eye(V)\n",
    "    for node in graph.nodes:\n",
    "        for edge in graph.in_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A1[node, edge_id] = -1\n",
    "        # Edge from appear to node    \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.in_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A1[node, E + V + edge_id] = -1\n",
    "         \n",
    "        for edge in graph.out_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A1[node, edge_id] = -1\n",
    "        # Edge from node to death\n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.out_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A1[node, E+V+edge_id] = -1\n",
    "            \n",
    "    # Network flow constraint\n",
    "    A2 = np.zeros((V, E + V + E_flow))\n",
    "    for node in graph.nodes:\n",
    "        for edge in graph.in_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A2[node, edge_id] = -1\n",
    "        \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.in_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A2[node, E+V+edge_id] = -1\n",
    "            \n",
    "            \n",
    "        for edge in graph.out_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A2[node, edge_id] = 1\n",
    "         \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.out_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A2[node, E+V+edge_id] = 1\n",
    "    \n",
    "    constraints = [\n",
    "        A0 @ x <= 0, \n",
    "        A1 @ x == 0,\n",
    "        A2 @ x == 0,\n",
    "    ]\n",
    "    \n",
    "    objective = cp.Minimize( c.T @ x)\n",
    "\n",
    "    return cp.Problem(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c0f94-ef47-4dbd-8f56-29e92a2f0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_flow = graph2ilp_flow(candidate_graph, hyperparams={\"node_factor\": -1, \"edge_factor\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ee36f-9271-4d73-a43a-b7fb8187beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_flow.solve()\n",
    "E = candidate_graph.number_of_edges()\n",
    "V = candidate_graph.number_of_nodes()\n",
    "print(\"ILP Status: \", ilp_flow.status)\n",
    "print(\"The optimal value is\", ilp_flow.value)\n",
    "print(\"x_e\")\n",
    "print(ilp_flow.variables()[0].value[:E])\n",
    "print(\"x_v\")\n",
    "print(ilp_flow.variables()[0].value[E:E+V])\n",
    "print(\"x_e_flow\")\n",
    "print(ilp_flow.variables()[0].value[E+V:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution2graph(solution, base_graph):\n",
    "    \n",
    "    solution_var = solution.variables()[0].value\n",
    "    \n",
    "    new_graph = nx.DiGraph()\n",
    "    \n",
    "    # Build nodes\n",
    "    x_v = solution_var[E:E+V]\n",
    "    picked_nodes = (x_v > 1e-6).nonzero()[0]  # small epsilon for solution variables\n",
    "    for node in picked_nodes:\n",
    "        node_features = base_graph.nodes[node]\n",
    "        new_graph.add_node(node, **node_features)\n",
    "    \n",
    "    # Build edges\n",
    "    original_edges = list(base_graph.edges)\n",
    "    x_e = solution_var[:E]\n",
    "    picked_edges = (x_e > 1e-6).nonzero()[0]\n",
    "    for edge in picked_edges:\n",
    "        new_graph.add_edge(*original_edges[edge])\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b33991-6fe8-49c8-a64c-be089d614805",
   "metadata": {},
   "outputs": [],
   "source": [
    "solved_graph_flow = solution2graph(ilp_flow, candidate_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba6d66-5cbc-48ae-9379-25dcc3d32588",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2) = plt.subplots(1,3, figsize=(32, 12))\n",
    "draw_graph(gt_graph, \"Ground truth graph\", ax=ax0, height=detections[0].shape[0])\n",
    "draw_graph(candidate_graph, \"Candidate graph\", ax=ax1, height=detections[0].shape[0])\n",
    "draw_graph(solved_graph_flow, f\"Network flow (no divisions) - cost: {ilp_flow.value:.3f}\", ax=ax2, height=detections[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recolor_detections(detections, graph, node_luts):\n",
    "    \"\"\"TODO cleanup\"\"\"\n",
    "    assert len(detections) == len(node_luts)\n",
    "    \n",
    "    out = []\n",
    "    n_tracks = 1\n",
    "    color_lookup_tables = []\n",
    "    \n",
    "    for t in tqdm(range(0, len(detections)), desc=\"Recoloring detections\"):\n",
    "        # print(f\"Time {t}\")\n",
    "        new_frame = np.zeros_like(detections[t])\n",
    "        color_lut = {}\n",
    "        for det_id, node_id in node_luts[t].items():\n",
    "            if node_id not in graph.nodes:\n",
    "                continue\n",
    "            # print(node_id)\n",
    "            edges = graph.in_edges(node_id)\n",
    "            if not edges:\n",
    "                new_frame[detections[t] == graph.nodes[node_id][\"detection_id\"]] = n_tracks\n",
    "                color_lut[graph.nodes[node_id][\"detection_id\"]] = n_tracks\n",
    "                # print(\"new node\")\n",
    "                # print(color_lut)\n",
    "                n_tracks += 1\n",
    "            else:\n",
    "                for v_tm1, u_t0 in edges:\n",
    "                    new_frame[detections[t] == graph.nodes[u_t0][\"detection_id\"]] = color_lookup_tables[t-1][graph.nodes[v_tm1][\"detection_id\"]]\n",
    "                    color_lut[graph.nodes[u_t0][\"detection_id\"]] = color_lookup_tables[t-1][graph.nodes[v_tm1][\"detection_id\"]]\n",
    "                    # print(color_lut)\n",
    "                \n",
    "        color_lookup_tables.append(color_lut)\n",
    "        out.append(new_frame)\n",
    "        \n",
    "\n",
    "    return np.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabad0a-6f48-4043-b7b7-f1c194c1c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recolored_gt = recolor_detections(y, gt_graph, gt_luts)\n",
    "detections_ilp_flow = recolor_detections(detections=detections, graph=solved_graph_flow, node_luts=candidate_luts)\n",
    "\n",
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "# visualize_tracks(viewer, y)\n",
    "viewer.add_labels(recolored_gt)\n",
    "viewer.add_labels(detections)\n",
    "viewer.add_labels(detections_ilp_flow)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86363039-ace7-49cb-83da-8988af221989",
   "metadata": {},
   "source": [
    "## Checkpoint 1\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 1: We have familiarized ourselves with the formulation of an ILP for linking and and have a feasible solution to a network flow.</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1abcf8e",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 3.2\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 3.2: Extend the network flow from Exercise 3.1 such that tracks can start and end at arbitrary time points</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0933530-2b53-491f-9f1b-524a30b495d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Exercise 3.2\n",
    "\n",
    "def graph2ilp_nodiv(graph, hyperparams):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    # Extend the graph with a single appear and death node\n",
    "    graph_flow = nx.DiGraph()\n",
    "    graph_flow.add_node(\"appear\", weight=0)\n",
    "    graph_flow.add_node(\"death\", weight=0)\n",
    "    \n",
    "    for n, time in graph.nodes(data=\"time\"):\n",
    "        graph_flow.add_node(n, weight=0)\n",
    "        graph_flow.add_edge(\"appear\", n, weight=hyperparams[\"cost_appear\"])\n",
    "        graph_flow.add_node(n, weight=0)\n",
    "        graph_flow.add_edge(n, \"death\", weight=hyperparams[\"cost_disappear\"])\n",
    "        \n",
    "        \n",
    "    edge_to_idx = {edge: i for i, edge in enumerate(graph.edges)}\n",
    "    edge_to_idx_flow = {edge: i for i, edge in enumerate(graph_flow.edges)}\n",
    "\n",
    "    E = graph.number_of_edges()\n",
    "    V = graph.number_of_nodes()\n",
    "    E_flow = graph_flow.number_of_edges()\n",
    "    x = cp.Variable(E + V + E_flow, boolean=True)\n",
    "    \n",
    "    c_e = hyperparams[\"edge_factor\"] * np.array([graph.get_edge_data(*e)[\"weight\"] for e in graph.edges])\n",
    "    c_v = hyperparams[\"node_factor\"] * np.array([v for k, v in graph.nodes(data=\"weight\")])\n",
    "    c_e_flow = np.array([graph_flow.get_edge_data(*e)[\"weight\"] for e in graph_flow.edges])\n",
    "\n",
    "    c = np.concatenate([c_e, c_v, c_e_flow])\n",
    "    \n",
    "    # constraint matrices: {E or V} x (E + V + E_flow)\n",
    "    # columns: c_e, c_v, c_e_flow\n",
    "    \n",
    "    # Edge consistency constraint\n",
    "    A0 = np.zeros((E, E + V + E_flow))\n",
    "    A0[:E, :E] = 2 * np.eye(E)\n",
    "    for edge in graph.edges:\n",
    "        edge_id = edge_to_idx[edge]\n",
    "        A0[edge_id, E + edge[0]] = -1\n",
    "        A0[edge_id, E + edge[1]] = -1\n",
    "    \n",
    "    # Node consistency constraint\n",
    "    A1 = np.zeros((V, E + V + E_flow))\n",
    "    A1[:V, E:E+V] = 2 * np.eye(V)\n",
    "    for node in graph.nodes:\n",
    "        for edge in graph.in_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A1[node, edge_id] = -1\n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.in_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A1[node, E + V + edge_id] = -1\n",
    "         \n",
    "        for edge in graph.out_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A1[node, edge_id] = -1\n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.out_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A1[node, E+V+edge_id] = -1\n",
    "            \n",
    "    # Network flow constraint\n",
    "    A2 = np.zeros((V, E + V + E_flow))\n",
    "    for node in graph.nodes:\n",
    "        for edge in graph.in_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A2[node, edge_id] = -1\n",
    "        \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.in_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A2[node, E+V+edge_id] = -1\n",
    "            \n",
    "            \n",
    "        for edge in graph.out_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A2[node, edge_id] = 1\n",
    "         \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.out_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A2[node, E+V+edge_id] = 1\n",
    "    \n",
    "    constraints = [\n",
    "        A0 @ x <= 0, \n",
    "        A1 @ x == 0,\n",
    "        A2 @ x == 0,\n",
    "    ]\n",
    "    \n",
    "    objective = cp.Minimize( c.T @ x)\n",
    "\n",
    "    return cp.Problem(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative formulation Exercise 3.2 following Malin-Mayor et al. (2021).\n",
    "\n",
    "# def graph2ilp_nodiv(graph, hyperparams):\n",
    "#     \"\"\"TODO cleanup\"\"\"\n",
    "#     edge_to_idx = {edge: i for i, edge in enumerate(graph.edges)}\n",
    "#     E = graph.number_of_edges()\n",
    "#     V = graph.number_of_nodes()\n",
    "#     x = cp.Variable(E + 3*V, boolean=True)\n",
    "    \n",
    "#     c_e = hyperparams[\"edge_factor\"] * np.array([graph.get_edge_data(*e)[\"weight\"] for e in graph.edges])\n",
    "#     # print(c_e)\n",
    "#     c_v = hyperparams[\"node_offset\"] + hyperparams[\"node_factor\"] * np.array([v for k, v in sorted(dict(graph.nodes(data=\"weight\")).items())])\n",
    "#     # print(c_v)\n",
    "#     c_va = np.ones(V) * hyperparams[\"cost_appear\"]\n",
    "#     c_vd = np.ones(V) * hyperparams[\"cost_disappear\"]\n",
    "#     c = np.concatenate([c_e, c_v, c_va, c_vd])\n",
    "    \n",
    "#     # constraint matrices: {E or V} x (E + 3V)\n",
    "#     # columns: c_e, c_v, c_va, c_vd\n",
    "    \n",
    "#     A0 = np.zeros((E, E + 3 * V))\n",
    "#     A0[:E, :E] = 2 * np.eye(E)\n",
    "#     for edge in graph.edges:\n",
    "#         edge_id = edge_to_idx[edge]\n",
    "#         A0[edge_id, E + edge[0]] = -1\n",
    "#         A0[edge_id, E + edge[1]] = -1\n",
    "    \n",
    "#     # Appear continuation\n",
    "#     A1 = np.zeros((V, E + 3 * V))\n",
    "#     A1[:, E:E+V] = -np.eye(V)\n",
    "#     A1[:, E+V:E+2*V] = np.eye(V)\n",
    "    \n",
    "#     for node in graph.nodes:\n",
    "#         out_edges = graph.out_edges(node)\n",
    "#         for edge in out_edges:\n",
    "#             edge_id = edge_to_idx[edge]\n",
    "#             A1[node, edge_id] = 1\n",
    "     \n",
    "#     # Disappear continuation\n",
    "#     A2 = np.zeros((V, E + 3 * V))\n",
    "#     A2[:, E:E+V] = np.eye(V)\n",
    "#     A2[:, E+2*V:E+3*V] = - np.eye(V)\n",
    "    \n",
    "#     for node in graph.nodes:\n",
    "#         in_edges = graph.in_edges(node)\n",
    "#         for edge in in_edges:\n",
    "#             edge_id = edge_to_idx[edge]\n",
    "#             A2[node, edge_id] = -1\n",
    "    \n",
    "#     constraints = [\n",
    "#         A0 @ x <= 0, \n",
    "#         A1 @ x == 0,\n",
    "#         A2 @ x == 0,\n",
    "#     ]   \n",
    "    \n",
    "#     objective = cp.Minimize( c.T @ x)\n",
    "    \n",
    "#     return cp.Problem(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a4b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_nodiv = graph2ilp_nodiv(candidate_graph, hyperparams={\"cost_appear\": 0.5, \"cost_disappear\": 0.5, \"node_factor\": -1, \"edge_factor\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9501be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_nodiv.solve()\n",
    "print(\"ILP Status: \", ilp_nodiv.status)\n",
    "print(\"The optimal value is\", ilp_nodiv.value)\n",
    "print(\"x_e\")\n",
    "E = candidate_graph.number_of_edges()\n",
    "V = candidate_graph.number_of_nodes()\n",
    "print(ilp_nodiv.variables()[0].value[:E])\n",
    "print(\"x_v\")\n",
    "print(ilp_nodiv.variables()[0].value[E:E+V])\n",
    "print(\"x_e_flow\")\n",
    "print(ilp_nodiv.variables()[0].value[E+V:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c56ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "solved_graph_nodiv = solution2graph(ilp_nodiv, candidate_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff76a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2) = plt.subplots(1,3, figsize=(32, 12))\n",
    "draw_graph(gt_graph, \"Ground truth graph\", ax=ax0, height=detections[0].shape[0])\n",
    "draw_graph(candidate_graph, \"Candidate graph\", ax=ax1, height=detections[0].shape[0])\n",
    "draw_graph(solved_graph_nodiv, f\"ILP solution (no divisions) - cost: {ilp_nodiv.value:.3f}\", ax=ax2, height=detections[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "recolored_gt = recolor_detections(y, gt_graph, gt_luts)\n",
    "detections_ilp_nodiv = recolor_detections(detections=detections, graph=solved_graph_nodiv, node_luts=candidate_luts)\n",
    "\n",
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "# visualize_tracks(viewer, y)\n",
    "viewer.add_labels(recolored_gt)\n",
    "viewer.add_labels(detections)\n",
    "viewer.add_labels(detections_ilp_nodiv)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa30a7-51ba-42cc-811b-d031ddaece36",
   "metadata": {},
   "source": [
    "## ILP model including divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605092c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 3.3\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 3.3: Complete yet another extension of the ILP such that it allows for cell divisions</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b0bf0-549e-416b-a895-5641d07da9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Exercise 3.3\n",
    "\n",
    "def graph2ilp_div(graph, hyperparams):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    # Extend the graph with a single appear and death node\n",
    "    graph_flow = nx.DiGraph()\n",
    "    graph_flow.add_node(\"appear\", weight=0)\n",
    "    graph_flow.add_node(\"death\", weight=0)\n",
    "    \n",
    "    for n, time in graph.nodes(data=\"time\"):\n",
    "        graph_flow.add_node(n, weight=0)\n",
    "        graph_flow.add_edge(\"appear\", n, weight=hyperparams[\"cost_appear\"])\n",
    "        graph_flow.add_node(n, weight=0)\n",
    "        graph_flow.add_edge(n, \"death\", weight=hyperparams[\"cost_disappear\"])\n",
    "        \n",
    "        \n",
    "    edge_to_idx = {edge: i for i, edge in enumerate(graph.edges)}\n",
    "    edge_to_idx_flow = {edge: i for i, edge in enumerate(graph_flow.edges)}\n",
    "\n",
    "    E = graph.number_of_edges()\n",
    "    V = graph.number_of_nodes()\n",
    "    E_flow = graph_flow.number_of_edges()\n",
    "    x = cp.Variable(E + V + E_flow, boolean=True)\n",
    "    \n",
    "    c_e = hyperparams[\"edge_factor\"] * np.array([graph.get_edge_data(*e)[\"weight\"] for e in graph.edges])\n",
    "    c_v = hyperparams[\"node_factor\"] * np.array([v for k, v in graph.nodes(data=\"weight\")])\n",
    "    c_e_flow = np.array([graph_flow.get_edge_data(*e)[\"weight\"] for e in graph_flow.edges])\n",
    "\n",
    "    c = np.concatenate([c_e, c_v, c_e_flow])\n",
    "    \n",
    "    # constraint matrices: {E or V} x (E + V + E_flow)\n",
    "    # columns: c_e, c_v, c_e_flow\n",
    "    \n",
    "    # Edge consistency constraint\n",
    "    A0 = np.zeros((E, E + V + E_flow))\n",
    "    A0[:E, :E] = 2 * np.eye(E)\n",
    "    for edge in graph.edges:\n",
    "        edge_id = edge_to_idx[edge]\n",
    "        A0[edge_id, E + edge[0]] = -1\n",
    "        A0[edge_id, E + edge[1]] = -1\n",
    "    \n",
    "    # Node consistency constraint\n",
    "    A1 = np.zeros((V, E + V + E_flow))\n",
    "    A1[:V, E:E+V] = 2 * np.eye(V)\n",
    "    for node in graph.nodes:\n",
    "        for edge in graph.in_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A1[node, edge_id] = -1\n",
    "        # Edge from appear to node    \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.in_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A1[node, E + V + edge_id] = -1\n",
    "         \n",
    "        for edge in graph.out_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A1[node, edge_id] = -1\n",
    "        # Edge from node to death\n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.out_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A1[node, E+V+edge_id] = -1\n",
    "            \n",
    "    # Network flow constraint\n",
    "    A2 = np.zeros((V, E + V + E_flow))\n",
    "    for node in graph.nodes:\n",
    "        for edge in graph.in_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A2[node, edge_id] = 1\n",
    "        \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.in_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A2[node, E + V+ edge_id] = 1\n",
    "            \n",
    "            \n",
    "        for edge in graph.out_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A2[node, edge_id] = -1\n",
    "         \n",
    "        if node in graph_flow.nodes:\n",
    "            for edge in graph_flow.out_edges(node):\n",
    "                edge_id = edge_to_idx_flow[edge]\n",
    "                A2[node, E + V + edge_id] = -1\n",
    "    \n",
    "    # At most 2 outgoing edges\n",
    "    A3 = np.zeros((V, E + V + E_flow))\n",
    "    A3[:, E:E+V] = -2 * np.eye(V)\n",
    "    \n",
    "    for node in graph.nodes:\n",
    "        for edge in graph.out_edges(node):\n",
    "            edge_id = edge_to_idx[edge]\n",
    "            A3[node, edge_id] = 1\n",
    "            \n",
    "    \n",
    "        for edge in graph_flow.out_edges(node):\n",
    "            edge_id = edge_to_idx_flow[edge]\n",
    "            A3[node, E + V + edge_id] = 2\n",
    "    \n",
    "    constraints = [\n",
    "        A0 @ x <= 0, \n",
    "        A1 @ x <= 0,\n",
    "        A2 @ x <= 0,\n",
    "        A3 @ x <= 0,\n",
    "    ]\n",
    "    \n",
    "    objective = cp.Minimize( c.T @ x)\n",
    "    \n",
    "    return cp.Problem(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Malin-Mayor et al. (2021) formulation\n",
    "\n",
    "# def graph2ilp_div(graph, hyperparams):\n",
    "#     \"\"\"TODO cleanup\"\"\"\n",
    "#     edge_to_idx = {edge: i for i, edge in enumerate(graph.edges)}\n",
    "#     E = graph.number_of_edges()\n",
    "#     V = graph.number_of_nodes()\n",
    "#     x = cp.Variable(E + 3*V, boolean=True)\n",
    "    \n",
    "#     c_e = hyperparams[\"edge_factor\"] * np.array([graph.get_edge_data(*e)[\"weight\"] for e in graph.edges])\n",
    "#     c_v = hyperparams[\"node_offset\"] + hyperparams[\"node_factor\"] * np.array([v for k, v in sorted(dict(graph.nodes(data=\"weight\")).items())])\n",
    "\n",
    "#     c_va = np.ones(V) * hyperparams[\"cost_appear\"]\n",
    "#     c_vd = np.ones(V) * hyperparams[\"cost_disappear\"]\n",
    "    \n",
    "#     c = np.concatenate([c_e, c_v, c_va, c_vd])\n",
    "    \n",
    "#     # constraint matrices: {E or V} x (E + 3V)\n",
    "#     # columns: ce, c_v, c_va, c_vd\n",
    "    \n",
    "#     A0 = np.zeros((E, E + 3 * V))\n",
    "#     A0[:E, :E] = 2 * np.eye(E)\n",
    "#     for edge in graph.edges:\n",
    "#         edge_id = edge_to_idx[edge]\n",
    "#         A0[edge_id, E + edge[0]] = -1\n",
    "#         A0[edge_id, E + edge[1]] = -1\n",
    "    \n",
    "#     # Appear continuation\n",
    "#     A1 = np.zeros((V, E + 3 * V))\n",
    "#     A1[:, E:E+V] = -np.eye(V)\n",
    "#     A1[:, E+V:E+2*V] = np.eye(V)\n",
    "    \n",
    "#     for node in graph.nodes:\n",
    "#         in_edges = graph.in_edges(node)\n",
    "#         for edge in in_edges:\n",
    "#             edge_id = edge_to_idx[edge]\n",
    "#             A1[node, edge_id] = 1\n",
    "     \n",
    "#     # Disappear continuation\n",
    "#     A2 = np.zeros((V, E + 3 * V))\n",
    "#     A2[:, E:E+V] = np.eye(V)\n",
    "#     A2[:, E+2*V:E+3*V] = - np.eye(V)\n",
    "    \n",
    "#     for node in graph.nodes:\n",
    "#         out_edges = graph.out_edges(node)\n",
    "#         for edge in out_edges:\n",
    "#             edge_id = edge_to_idx[edge]\n",
    "#             A2[node, edge_id] = -1\n",
    "    \n",
    "#     # At most 2 outgoing edges\n",
    "#     A3 = np.zeros((V, E + 3*V))\n",
    "#     A3[:, E:E+V] = -2*np.eye(V)\n",
    "#     A3[:, E+2*V:E+3*V] = 2 * np.eye(V)\n",
    "    \n",
    "#     for node in graph.nodes:\n",
    "#         out_edges = graph.out_edges(node)\n",
    "#         for edge in out_edges:\n",
    "#             edge_id = edge_to_idx[edge]\n",
    "#             A3[node, edge_id] = 1\n",
    "    \n",
    "#     constraints = [\n",
    "#         A0 @ x <= 0, \n",
    "#         A1 @ x == 0,\n",
    "#         A2 @ x <= 0,\n",
    "#         A3 @ x <= 0,\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     objective = cp.Minimize( c.T @ x)\n",
    "\n",
    "    \n",
    "#     return cp.Problem(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_div = graph2ilp_div(candidate_graph, hyperparams={\"cost_appear\": 0.15, \"cost_disappear\": 0.5, \"node_offset\": 0, \"node_factor\": -1, \"edge_factor\": 0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dedc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilp_div.solve()\n",
    "print(\"ILP Status: \", ilp_div.status)\n",
    "print(\"The optimal value is\", ilp_div.value)\n",
    "print(\"x_e\")\n",
    "E = candidate_graph.number_of_edges()\n",
    "V = candidate_graph.number_of_nodes()\n",
    "print(ilp_div.variables()[0].value[:E])\n",
    "print(\"x_v\")\n",
    "print(ilp_div.variables()[0].value[E:E+V])\n",
    "print(\"x_e_flow\")\n",
    "print(ilp_div.variables()[0].value[E+V:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "solved_graph_div = solution2graph(ilp_div, candidate_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df65faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_solved_div = recolor_detections(detections=detections, graph=solved_graph_div, node_luts=candidate_luts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ed8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "viewer.add_labels(recolored_gt)\n",
    "viewer.add_labels(detections)\n",
    "viewer.add_labels(det_solved_div)\n",
    "viewer.grid.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e31e8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(2,2, figsize=(24, 16))\n",
    "draw_graph(candidate_graph, \"Candidate graph\", ax=ax0)\n",
    "draw_graph(solved_graph_div, f\"ILP solution (with divisions) - cost: {ilp_div.value:.3f}\", ax=ax1)\n",
    "draw_graph(gt_graph, \"Ground truth graph\", ax=ax2)\n",
    "draw_graph(solved_graph_nodiv, f\"ILP solution (no divisions) - cost: {ilp_nodiv.value:.3f}\", ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b009202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
